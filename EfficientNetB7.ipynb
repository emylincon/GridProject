{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid_project2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvCgzo6D+FBei3/J8P+Bs8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emylincon/GridProject/blob/master/EfficientNetB7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMZ8EAkF_5MN",
        "outputId": "a7c7c22e-efc7-4324-a472-160310eb6a41"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GiAlhxMAL95",
        "outputId": "e3b1cf12-3eb6-4749-936b-9adf02763ab9"
      },
      "source": [
        "! cd \"drive/MyDrive/dataset/\"\n",
        "! ls \"drive/MyDrive/dataset/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bimodel  my_model.h5  test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aex5B16HCtQ3",
        "outputId": "45b223c1-6298-4026-9dfe-f16f60478051"
      },
      "source": [
        "! pip3 install keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Installing collected packages: keras-applications, keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUrhmlD-DrIz"
      },
      "source": [
        "# USING EfficientNetB7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfwI3d4ACzHQ",
        "outputId": "08256f4d-1a77-4a7d-ee50-87b9772566d9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "\n",
        "HEIGHT = 300\n",
        "WIDTH = 300\n",
        "\n",
        "base_model = EfficientNetB7(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258080768/258076736 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krY4ECXnDkU4",
        "outputId": "73a6c206-f06e-42f4-be02-ca096535c9e7"
      },
      "source": [
        "import os\n",
        "os.chdir('drive/MyDrive/dataset/')\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe-rCfX0EDDD"
      },
      "source": [
        "# DATA PREPROCESSING AND AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER2vbAUPD1bb",
        "outputId": "dff0eaf2-fb79-4ec7-d7a2-fd107d1dce1b"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAIN_DIR = \"train/\"\n",
        "HEIGHT = 300\n",
        "WIDTH = 300\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "test_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'test/',\n",
        "        target_size=(300, 300),\n",
        "        batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 374 images belonging to 2 classes.\n",
            "Found 90 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSpY01vBE2KL"
      },
      "source": [
        "# BUILDING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boIsvB4JExTg"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "class_list = os.listdir(\"train/\")\n",
        "FC_LAYERS = [1024, 1024]\n",
        "dropout = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=len(class_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO8OHD_dFHXn"
      },
      "source": [
        "# COMPLILE AND TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ThJgmUFDaP",
        "outputId": "3159c463-1d84-4b16-8e6c-9db89fdca17d"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 16\n",
        "num_train_images = 370\n",
        "\n",
        "adam = Adam(lr=0.00001)\n",
        "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "filepath=\"../eff_checkpoint/\" + \"EFF\" + \"_model_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=16, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-86097a931ca2>:18: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.7967\n",
            "Epoch 00001: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 221s 10s/step - loss: 0.5071 - accuracy: 0.7967\n",
            "Epoch 2/30\n",
            " 3/23 [==>...........................] - ETA: 2:17 - loss: 0.4727 - accuracy: 0.7500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.8315\n",
            "Epoch 00002: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 235s 10s/step - loss: 0.4824 - accuracy: 0.8315\n",
            "Epoch 3/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.8242\n",
            "Epoch 00003: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 249s 11s/step - loss: 0.5485 - accuracy: 0.8242\n",
            "Epoch 4/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.8478\n",
            "Epoch 00004: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 248s 11s/step - loss: 0.4875 - accuracy: 0.8478\n",
            "Epoch 5/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8681\n",
            "Epoch 00005: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 252s 11s/step - loss: 0.3957 - accuracy: 0.8681\n",
            "Epoch 6/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.8681\n",
            "Epoch 00006: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 254s 11s/step - loss: 0.4214 - accuracy: 0.8681\n",
            "Epoch 7/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.8913\n",
            "Epoch 00007: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 247s 11s/step - loss: 0.3267 - accuracy: 0.8913\n",
            "Epoch 8/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5724 - accuracy: 0.8242\n",
            "Epoch 00008: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 253s 11s/step - loss: 0.5724 - accuracy: 0.8242\n",
            "Epoch 9/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8901\n",
            "Epoch 00009: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 244s 11s/step - loss: 0.3503 - accuracy: 0.8901\n",
            "Epoch 10/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8370\n",
            "Epoch 00010: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 256s 11s/step - loss: 0.5089 - accuracy: 0.8370\n",
            "Epoch 11/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8804\n",
            "Epoch 00011: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 255s 11s/step - loss: 0.3657 - accuracy: 0.8804\n",
            "Epoch 12/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.8242\n",
            "Epoch 00012: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 250s 11s/step - loss: 0.4743 - accuracy: 0.8242\n",
            "Epoch 13/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.8791\n",
            "Epoch 00013: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 253s 11s/step - loss: 0.3966 - accuracy: 0.8791\n",
            "Epoch 14/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.8571\n",
            "Epoch 00014: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 253s 11s/step - loss: 0.5312 - accuracy: 0.8571\n",
            "Epoch 15/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.8859\n",
            "Epoch 00015: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 253s 11s/step - loss: 0.4111 - accuracy: 0.8859\n",
            "Epoch 16/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9176\n",
            "Epoch 00016: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 251s 11s/step - loss: 0.3239 - accuracy: 0.9176\n",
            "Epoch 17/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9076\n",
            "Epoch 00017: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 255s 11s/step - loss: 0.2694 - accuracy: 0.9076\n",
            "Epoch 18/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.8967\n",
            "Epoch 00018: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 257s 11s/step - loss: 0.4107 - accuracy: 0.8967\n",
            "Epoch 19/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8626\n",
            "Epoch 00019: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 255s 11s/step - loss: 0.3870 - accuracy: 0.8626\n",
            "Epoch 20/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8804\n",
            "Epoch 00020: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 257s 11s/step - loss: 0.3790 - accuracy: 0.8804\n",
            "Epoch 21/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.8956\n",
            "Epoch 00021: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 251s 11s/step - loss: 0.2975 - accuracy: 0.8956\n",
            "Epoch 22/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9176\n",
            "Epoch 00022: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 252s 11s/step - loss: 0.2109 - accuracy: 0.9176\n",
            "Epoch 23/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9185\n",
            "Epoch 00023: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 264s 11s/step - loss: 0.2635 - accuracy: 0.9185\n",
            "Epoch 24/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.8967\n",
            "Epoch 00024: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 243s 11s/step - loss: 0.2673 - accuracy: 0.8967\n",
            "Epoch 25/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9185\n",
            "Epoch 00025: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 257s 11s/step - loss: 0.2484 - accuracy: 0.9185\n",
            "Epoch 26/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.9011\n",
            "Epoch 00026: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 251s 11s/step - loss: 0.3944 - accuracy: 0.9011\n",
            "Epoch 27/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9402\n",
            "Epoch 00027: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 247s 11s/step - loss: 0.1512 - accuracy: 0.9402\n",
            "Epoch 28/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9341\n",
            "Epoch 00028: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 244s 11s/step - loss: 0.2078 - accuracy: 0.9341\n",
            "Epoch 29/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9185\n",
            "Epoch 00029: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 252s 11s/step - loss: 0.2759 - accuracy: 0.9185\n",
            "Epoch 30/30\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.9121\n",
            "Epoch 00030: saving model to ../eff_checkpoint/EFF_model_weights.h5\n",
            "23/23 [==============================] - 247s 11s/step - loss: 0.3163 - accuracy: 0.9121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf2qb4KpFr-_",
        "outputId": "5d5dc2dd-e79b-412a-d45b-da7ac957c934"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1ua6E3Yj-Hz"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS9HMQGMkA8c",
        "outputId": "698bac97-ba72-4081-83a5-c53498c4f280"
      },
      "source": [
        "history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9120879173278809"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrhIMCSBkGyM"
      },
      "source": [
        "predictions1 = finetune_model.predict(x=validation_generator, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKYULDoGkW7M"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-RKVH6LkyH0"
      },
      "source": [
        "cm = confusion_matrix(y_true=validation_generator.classes, y_pred=np.argmax(predictions1, axis=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcvsWtV8k0O7",
        "outputId": "c6a3b8ae-6a45-4002-b75e-86f40251e81a"
      },
      "source": [
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29, 16],\n",
              "       [22, 23]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "W9OU0lsfk06M",
        "outputId": "ee20aa15-c89e-43da-860c-dfbae87dd2bb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.title('Confusion matrix ')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA7nLGk6k_C3",
        "outputId": "ea811076-5472-4c7d-f14f-2aa26ada337f"
      },
      "source": [
        "finetune_model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 87s 7s/step - loss: 0.4983 - accuracy: 0.8889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4983006715774536, 0.8888888955116272]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auS0uqOHmEzl",
        "outputId": "e1a6a0be-43b7-469c-ca67-b6df322c2095"
      },
      "source": [
        "validation_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ec': 0, 'nec': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ASY4CY1myt1"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmYQNtowlUPX"
      },
      "source": [
        "def get_prediction(image_path):\n",
        "  names = ['EC', 'NEC']\n",
        "  img = load_img(image_path, target_size=(300, 300))\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  preds = finetune_model.predict(x)\n",
        "  return names[preds.argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18nqatUgmcQp",
        "outputId": "23d21678-5355-40bc-a542-a1727a2a26b5"
      },
      "source": [
        "base_ec = 'test/ec/'\n",
        "ecs = os.listdir(base_ec)\n",
        "err = []\n",
        "for i in ecs:\n",
        "  if get_prediction(base_ec+i) == 'NEC':\n",
        "    err.append(i)\n",
        "\n",
        "print(err)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['000206.jpg', '000210.jpg', '000231.jpg', '000189.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTkY-yfxmelf",
        "outputId": "da33c966-a852-44b7-c69e-75efaed69256"
      },
      "source": [
        "base_nec = 'test/nec/'\n",
        "necs = os.listdir(base_nec)\n",
        "err = []\n",
        "for i in necs:\n",
        "  if get_prediction(base_nec+i) == 'EC':\n",
        "    err.append(i)\n",
        "\n",
        "print(err)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['000210.jpg', '000204.jpg', '000216.jpg', '000197.jpg', '000213.jpg', '000209.jpg', '000219.jpg', '000211.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ9uEMbdnWxm"
      },
      "source": [
        "finetune_model.save('eff1_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHxXjoo8oXzW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}